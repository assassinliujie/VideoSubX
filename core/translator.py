import pandas as pd
import json
import concurrent.futures
from core.translate_lines import translate_lines
from core.summarizer import search_things_to_note_in_prompt
from core.utils.text_trim import check_len_then_trim
from core.subtitle_generator import align_timestamp
from core.utils import *
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn
from difflib import SequenceMatcher
from core.utils.paths import *
console = Console()

# æ‹†åˆ†æ–‡æœ¬å—çš„å‡½æ•°
def split_chunks_by_chars(chunk_size, max_i): 
    """æ ¹æ®å­—ç¬¦æ•°å°†æ–‡æœ¬æ‹†åˆ†ä¸ºå—ï¼Œè¿”å›å¤šè¡Œæ–‡æœ¬å—åˆ—è¡¨"""
    with open(_3_2_SPLIT_BY_MEANING, "r", encoding="utf-8") as file:
        sentences = file.read().strip().split('\n')

    chunks = []
    chunk = ''
    sentence_count = 0
    for sentence in sentences:
        if len(chunk) + len(sentence + '\n') > chunk_size or sentence_count == max_i:
            chunks.append(chunk.strip())
            chunk = sentence + '\n'
            sentence_count = 1
        else:
            chunk += sentence + '\n'
            sentence_count += 1
    chunks.append(chunk.strip())
    return chunks

# è·å–ç›¸é‚»å—çš„ä¸Šä¸‹æ–‡
def get_previous_content(chunks, chunk_index):
    return None if chunk_index == 0 else chunks[chunk_index - 1].split('\n')[-8:] # è·å–æœ€å8è¡Œä½œä¸ºä¸Šä¸‹æ–‡
def get_after_content(chunks, chunk_index):
    return None if chunk_index == len(chunks) - 1 else chunks[chunk_index + 1].split('\n')[:8] # è·å–å‰8è¡Œä½œä¸ºä¸Šä¸‹æ–‡

# ğŸ” ç¿»è¯‘å•ä¸ªå—
def translate_chunk(chunk, chunks, theme_prompt, i):
    things_to_note_prompt = search_things_to_note_in_prompt(chunk)
    previous_content_prompt = get_previous_content(chunks, i)
    after_content_prompt = get_after_content(chunks, i)
    translation, english_result = translate_lines(chunk, previous_content_prompt, after_content_prompt, things_to_note_prompt, theme_prompt, i)
    return i, english_result, translation

# è®¡ç®—ç›¸ä¼¼åº¦å‡½æ•°
def similar(a, b):
    return SequenceMatcher(None, a, b).ratio()

# ğŸš€ ç¿»è¯‘æ‰€æœ‰å—çš„ä¸»å‡½æ•°
@check_file_exists(_4_2_TRANSLATION)
def translate_all():
    console.print("[bold green]Start Translating All...[/bold green]")
    chunks = split_chunks_by_chars(chunk_size=600, max_i=10)
    with open(_4_1_TERMINOLOGY, 'r', encoding='utf-8') as file:
        theme_prompt = json.load(file).get('theme')

    # ğŸ”„ ä½¿ç”¨å¹¶å‘æ‰§è¡Œç¿»è¯‘
    with Progress(SpinnerColumn(), TextColumn("[progress.description]{task.description}"), transient=True) as progress:
        task = progress.add_task("[cyan]Translating chunks...", total=len(chunks))
        with concurrent.futures.ThreadPoolExecutor(max_workers=load_key("max_workers")) as executor:
            futures = []
            for i, chunk in enumerate(chunks):
                future = executor.submit(translate_chunk, chunk, chunks, theme_prompt, i)
                futures.append(future)
            results = []
            for future in concurrent.futures.as_completed(futures):
                results.append(future.result())
                progress.update(task, advance=1)

    results.sort(key=lambda x: x[0])  # æŒ‰åŸå§‹é¡ºåºæ’åºç»“æœ
    
    # ğŸ’¾ ä¿å­˜ç»“æœåˆ°åˆ—è¡¨å’ŒExcelæ–‡ä»¶
    src_text, trans_text = [], []
    for i, chunk in enumerate(chunks):
        chunk_lines = chunk.split('\n')
        src_text.extend(chunk_lines)
        
        # è®¡ç®—å½“å‰å—ä¸ç¿»è¯‘ç»“æœçš„ç›¸ä¼¼åº¦
        chunk_text = ''.join(chunk_lines).lower()
        matching_results = [(r, similar(''.join(r[1].split('\n')).lower(), chunk_text)) 
                          for r in results]
        best_match = max(matching_results, key=lambda x: x[1])
        
        # æ£€æŸ¥ç›¸ä¼¼åº¦å¹¶å¤„ç†å¼‚å¸¸
        if best_match[1] < 0.9:
            console.print(f"[yellow]Warning: No matching translation found for chunk {i}[/yellow]")
            raise ValueError(f"Translation matching failed (chunk {i})")
        elif best_match[1] < 1.0:
            console.print(f"[yellow]Warning: Similar match found (chunk {i}, similarity: {best_match[1]:.3f})[/yellow]")
            
        trans_text.extend(best_match[0][2].split('\n'))
    
    # è£å‰ªè¿‡é•¿çš„ç¿»è¯‘æ–‡æœ¬
    df_text = pd.read_excel(_2_CLEANED_CHUNKS)
    df_text['text'] = df_text['text'].str.strip('"').str.strip()
    df_translate = pd.DataFrame({'Source': src_text, 'Translation': trans_text})
    subtitle_output_configs = [('trans_subs_for_audio.srt', ['Translation'])]
    df_time = align_timestamp(df_text, df_translate, subtitle_output_configs, output_dir=None, for_display=False)
    console.print(df_time)
    # å¯¹ df_time['Translation'] åº”ç”¨ check_len_then_trimï¼Œä»…å½“ duration > MIN_TRIM_DURATION æ—¶
    df_time['Translation'] = df_time.apply(lambda x: check_len_then_trim(x['Translation'], x['duration']) if x['duration'] > load_key("min_trim_duration") else x['Translation'], axis=1)
    console.print(df_time)
    
    df_time.to_excel(_4_2_TRANSLATION, index=False)
    console.print("[bold green]âœ… Translation completed and results saved.[/bold green]")

if __name__ == '__main__':
    translate_all()