import os
import pandas as pd
import warnings
from core.spacy_utils.load_nlp_model import init_nlp, ROUGH_SPLIT_FILE
from core.utils.config_utils import load_key, get_joiner
from rich import print as rprint

warnings.filterwarnings("ignore", category=FutureWarning)


def rough_split(nlp):
    """
    æŒ‰æ ‡ç‚¹åˆ†å¥ï¼š
    1. å…ˆæ ¹æ®æ—¶é—´é—´éš”æŠŠæ–‡æœ¬åˆ†æˆå¤šä¸ªæ®µè½
    2. å¯¹æ¯ä¸ªæ®µè½ç”¨ spacy æŒ‰æ ‡ç‚¹åˆ†å¥
    è¿™æ ·æ—¢ä¿ç•™äº† spacy çš„æ™ºèƒ½åˆ†å¥ï¼Œåˆèƒ½åœ¨æ—¶é—´æ–­ç‚¹å¤„å¼ºåˆ¶åˆ†å¼€ã€‚
    """
    whisper_language = load_key("whisper.language")
    language = load_key("whisper.detected_language") if whisper_language == 'auto' else whisper_language
    joiner = get_joiner(language)
    rprint(f"[blue]ğŸ” Using {language} language joiner: '{joiner}'[/blue]")
    
    # è¯»å–æ—¶é—´é—´éš”é˜ˆå€¼
    time_gap_threshold = load_key("subtitle.time_split_threshold")
    rprint(f"[blue]â±ï¸ Time gap threshold: {time_gap_threshold}s[/blue]")
    
    chunks = pd.read_excel("output/log/cleaned_chunks.xlsx")
    chunks['text'] = chunks['text'].apply(lambda x: str(x).strip('"').strip())
    
    # ç¬¬ä¸€æ­¥ï¼šæ ¹æ®æ—¶é—´é—´éš”åˆ†æˆå¤šä¸ªæ®µè½
    paragraphs = []  # æ¯ä¸ªæ®µè½æ˜¯ä¸€ä¸ªè¯åˆ—è¡¨
    current_paragraph = []
    prev_end_time = None
    
    for idx, row in chunks.iterrows():
        word = row['text']
        start_time = row['start']
        end_time = row['end']
        
        if not word or str(word).isspace():
            continue
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¼€å§‹æ–°æ®µè½
        if prev_end_time is not None:
            time_gap = start_time - prev_end_time
            if time_gap > time_gap_threshold:
                # ä¿å­˜å½“å‰æ®µè½ï¼Œå¼€å§‹æ–°æ®µè½
                if current_paragraph:
                    paragraphs.append(current_paragraph)
                current_paragraph = []
                rprint(f"[dim]ğŸ“ Time gap {time_gap:.2f}s at {start_time:.2f}s[/dim]")
        
        current_paragraph.append(word)
        prev_end_time = end_time
    
    # ä¿å­˜æœ€åä¸€ä¸ªæ®µè½
    if current_paragraph:
        paragraphs.append(current_paragraph)
    
    rprint(f"[blue]ğŸ“ Split into {len(paragraphs)} paragraphs based on time gaps[/blue]")
    
    # ç¬¬äºŒæ­¥ï¼šå¯¹æ¯ä¸ªæ®µè½ç”¨ spacy åˆ†å¥
    all_sentences = []
    
    for paragraph_words in paragraphs:
        # ç”¨ joiner æ‹¼æ¥æ®µè½å†…çš„è¯
        paragraph_text = joiner.join(paragraph_words)
        
        # ç”¨ spacy åˆ†å¥
        doc = nlp(paragraph_text)
        
        if not doc.has_annotation("SENT_START"):
            # å¦‚æœ spacy æ— æ³•åˆ†å¥ï¼Œä¿ç•™æ•´ä¸ªæ®µè½
            all_sentences.append(paragraph_text)
            continue
        
        # å¤„ç† spacy åˆ†å‡ºçš„å¥å­ï¼ˆåˆå¹¶ - å’Œ ... å¼€å¤´/ç»“å°¾çš„æƒ…å†µï¼‰
        current_sentence = []
        for sent in doc.sents:
            text = sent.text.strip()
            if not text:
                continue
            
            if current_sentence and (
                text.startswith('-') or 
                text.startswith('...') or
                current_sentence[-1].endswith('-') or
                current_sentence[-1].endswith('...')
            ):
                current_sentence.append(text)
            else:
                if current_sentence:
                    all_sentences.append(' '.join(current_sentence))
                    current_sentence = []
                current_sentence.append(text)
        
        if current_sentence:
            all_sentences.append(' '.join(current_sentence))

    # å†™å…¥æ–‡ä»¶
    with open(ROUGH_SPLIT_FILE, "w", encoding="utf-8") as output_file:
        for i, sentence in enumerate(all_sentences):
            if i > 0 and sentence.strip() in [',', '.', 'ï¼Œ', 'ã€‚', 'ï¼Ÿ', 'ï¼']:
                # å¦‚æœå½“å‰è¡Œåªæœ‰æ ‡ç‚¹ï¼Œåˆå¹¶åˆ°ä¸Šä¸€è¡Œ
                output_file.seek(output_file.tell() - 1, os.SEEK_SET)
                output_file.write(sentence)
            else:
                output_file.write(sentence + "\n")
    
    rprint(f"[green]âœ… Split into {len(all_sentences)} sentences[/green]")
    rprint(f"[green]ğŸ’¾ Saved to â†’ `{ROUGH_SPLIT_FILE}`[/green]")

if __name__ == "__main__":
    nlp = init_nlp()
    rough_split(nlp)
